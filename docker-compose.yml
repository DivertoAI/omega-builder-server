services:
  omega:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: omega-builder
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      OMEGA_PREVIEW_ROOT: /preview
      PYTHONUNBUFFERED: "1"
      PYTHONPATH: /app
      OMEGA_RESET_ON_START: "1"

      # --- Models: stick to o3 (planner) + gpt-5 (coder) ---
      OMEGA_PLANNER_MODEL: "o3"
      OMEGA_CODEGEN_MODEL: "gpt-5"
      OMEGA_LLM_MODEL: "gpt-5"
      OMEGA_IMAGE_MODEL: "gpt-image-1"

      # Point the app to the Redis service (compose DNS name is 'redis')
      REDIS_URL: "redis://redis:6379/0"

      # ==== AI-VM wiring (remote compile/repair) ====
      OMEGA_COMPILE_REMOTE: "1"
      OMEGA_COMPILE_LOCAL_FALLBACK: "1"
      AI_VM_URL: "http://ai-vm:8080"

      # Ensure omega writes artifacts where ai-vm can see them
      OMEGA_STAGING_ROOT: "/workspace/staging"

      # Queues (build + assets) — must match ai-vm
      AI_VM_QUEUE_KEY: "queue:build"
      AI_VM_QUEUE_ASSETS: "queue:assets"

      # Optional safety/time caps
      OMEGA_MAX_AGENT_ROUNDS: "8"
      OMEGA_DEFAULT_WALL_CLOCK_SEC: "900"
    volumes:
      - .:/app:delegated                 # backend code path
      - .:/workspace:delegated           # shared project root (bind mount -> visible on host)
      - omega_workspace:/app/workspace/.omega
      - ./preview:/preview:rw
    command: >
      python -m uvicorn backend.main:app
      --host 0.0.0.0
      --port 8000
    tty: true
    stdin_open: true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request,sys; urllib.request.urlopen('http://localhost:8000/api/health', timeout=3); sys.exit(0)"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 90s
    depends_on:
      redis:
        condition: service_healthy
      ai-vm:
        condition: service_healthy

  ai-vm:
    build:
      context: ./ai-vm
      dockerfile: docker/Dockerfile
    container_name: omega-ai-vm
    ports:
      - "8080:8080"
    env_file:
      - .env
    environment:
      WORKSPACE_DIR: "/workspace"
      FLUTTER_VERSION: "3.27.1"
      CI: "true"
      REDIS_URL: "redis://redis:6379/0"

      # Queues (build + assets) — must match omega
      AI_VM_QUEUE_KEY: "queue:build"
      AI_VM_QUEUE_ASSETS: "queue:assets"

      # Image model for assets worker
      OMEGA_IMAGE_MODEL: "gpt-image-1"

      # Make sure Python can import the FastAPI app package
      PYTHONPATH: "/workspace/ai-vm:/workspace"
    working_dir: /workspace
    volumes:
      - .:/workspace:delegated           # shared project root (bind mount -> visible on host)
      - ai_vm_pub_cache:/home/flutter/.pub-cache
      - ai_vm_gradle_cache:/home/flutter/.gradle
    command: >
      bash -lc '
        export PYTHONPATH="/workspace/ai-vm:/workspace:$${PYTHONPATH}";
        # Run the assets worker in background; keep API (uvicorn) as PID 1
        nohup python3 -u /workspace/ai-vm/workers/assets_worker.py >/tmp/assets_worker.log 2>&1 &
        # IMPORTANT: point --app-dir to the folder that contains main.py and its sibling modules
        exec python3 -m uvicorn main:app --host 0.0.0.0 --port 8080 --app-dir /workspace/ai-vm/app
      '
    tty: true
    stdin_open: true
    restart: unless-stopped
    healthcheck:
      # ai-vm exposes /health (not /api/health)
      test: ["CMD", "python3", "-c", "import urllib.request,sys; urllib.request.urlopen('http://localhost:8080/api/health', timeout=3); sys.exit(0)"]
      interval: 30s
      timeout: 8s
      retries: 5
      start_period: 90s
    depends_on:
      redis:
        condition: service_healthy

  redis:
    image: redis:7-alpine
    container_name: omega-redis
    command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "redis-cli", "PING"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    # ports:
    #   - "6379:6379"

volumes:
  omega_workspace:
  ai_vm_pub_cache:
  ai_vm_gradle_cache: